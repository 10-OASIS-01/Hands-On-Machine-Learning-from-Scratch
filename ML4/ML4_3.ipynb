{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T07:40:38.038305Z",
     "start_time": "2024-12-11T07:40:37.303579Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from CART import DecisionTree\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from CART import train_test_split_data, evaluate_classification, evaluate_regression"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 房价回归树",
   "id": "c022eb5f07ca6b2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T07:42:51.711846Z",
     "start_time": "2024-12-11T07:40:38.047311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load California Housing dataset\n",
    "california = fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the decision tree for regression\n",
    "reg_tree = DecisionTree(task='regression', min_samples_split=2, min_impurity_decrease=1e-7)\n",
    "reg_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = reg_tree.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = evaluate_regression(y_test, y_pred)\n",
    "print(f\"California Housing Regression MSE: {mse:.4f}\")\n"
   ],
   "id": "8449547dacfd43f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California Housing Regression MSE: 0.5036\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### iris分类树",
   "id": "7122bbb00629b909"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T07:42:51.952521Z",
     "start_time": "2024-12-11T07:42:51.858050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the decision tree for classification\n",
    "clf_tree = DecisionTree(task='classification', min_samples_split=2, min_impurity_decrease=1e-7)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "# 打印决策树结构\n",
    "print(\"Decision Tree Structure:\")\n",
    "clf_tree.print_tree()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf_tree.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = evaluate_classification(y_test, y_pred)\n",
    "print(f\"Iris Classification Accuracy: {accuracy:.4f}\")\n"
   ],
   "id": "e6f8c8649b6c9e25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Structure:\n",
      "Feature 2 <= 1.9\n",
      "|-- Left: Leaf: 0\n",
      "|-- Right: Feature 2 <= 4.7\n",
      "|-- Right: |-- Left: Feature 3 <= 1.6\n",
      "|-- Right: |-- Left: |-- Left: Leaf: 1\n",
      "|-- Right: |-- Left: |-- Right: Leaf: 2\n",
      "|-- Right: |-- Right: Feature 3 <= 1.7\n",
      "|-- Right: |-- Right: |-- Left: Feature 2 <= 4.9\n",
      "|-- Right: |-- Right: |-- Left: |-- Left: Leaf: 1\n",
      "|-- Right: |-- Right: |-- Left: |-- Right: Feature 3 <= 1.5\n",
      "|-- Right: |-- Right: |-- Left: |-- Right: |-- Left: Leaf: 2\n",
      "|-- Right: |-- Right: |-- Left: |-- Right: |-- Right: Feature 0 <= 6.7\n",
      "|-- Right: |-- Right: |-- Left: |-- Right: |-- Right: |-- Left: Leaf: 1\n",
      "|-- Right: |-- Right: |-- Left: |-- Right: |-- Right: |-- Right: Leaf: 2\n",
      "|-- Right: |-- Right: |-- Right: Feature 2 <= 4.8\n",
      "|-- Right: |-- Right: |-- Right: |-- Left: Feature 0 <= 5.9\n",
      "|-- Right: |-- Right: |-- Right: |-- Left: |-- Left: Leaf: 1\n",
      "|-- Right: |-- Right: |-- Right: |-- Left: |-- Right: Leaf: 2\n",
      "|-- Right: |-- Right: |-- Right: |-- Right: Leaf: 2\n",
      "Iris Classification Accuracy: 1.0000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在决策树的构建过程中，递归分枝（递归地划分数据集）是核心步骤之一。然而，为了防止过拟合以及确保树的结构合理，我们需要设定一些终止条件来决定何时停止进一步分枝。以下将结合我们之前实现的CART（分类与回归树）算法代码，详细介绍树递归分枝的终止条件及其对应的代码，并简要说明递归分枝的过程。\n",
    "\n",
    "## 树递归分枝的终止条件\n",
    "\n",
    "在我们的实现中，决策树的递归分枝主要有以下两个终止条件：\n",
    "\n",
    "1. **最小样本分裂数（`min_samples_split`）**：\n",
    "   - **定义**：如果一个节点中的样本数少于设定的最小样本分裂数，则不再对该节点进行分裂，直接将其作为叶节点。\n",
    "   - **作用**：防止树过于细致地拟合训练数据，减少过拟合风险。\n",
    "\n",
    "2. **最小不纯度减少（`min_impurity_decrease`）**：\n",
    "   - **定义**：如果通过分裂一个节点所带来的不纯度（如基尼指数或方差）的减少量小于设定的阈值，则不进行分裂，直接将该节点作为叶节点。\n",
    "   - **作用**：确保每次分裂都有足够的意义，避免无效分裂。\n",
    "\n",
    "\n",
    "```\n",
    "def _build_tree(self, X, y):\n",
    "    \"\"\"\n",
    "    递归地构建树。\n",
    "    \"\"\"\n",
    "    num_samples, num_features = X.shape\n",
    "\n",
    "    # 终止条件1：样本数小于最小分裂数\n",
    "    if num_samples < self.min_samples_split:\n",
    "        leaf_value = self._calculate_leaf_value(y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    # 寻找最佳分裂\n",
    "    best_feature, best_threshold, best_gain = self._best_split(X, y, num_features)\n",
    "\n",
    "    # 终止条件2：不纯度减少量小于阈值\n",
    "    if best_gain < self.min_impurity_decrease:\n",
    "        leaf_value = self._calculate_leaf_value(y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    # 分裂节点\n",
    "    left_indices = X[:, best_feature] <= best_threshold\n",
    "    X_left, y_left = X[left_indices], y[left_indices]\n",
    "    X_right, y_right = X[~left_indices], y[~left_indices]\n",
    "\n",
    "    # 递归构建左子树和右子树\n",
    "    left_child = self._build_tree(X_left, y_left)\n",
    "    right_child = self._build_tree(X_right, y_right)\n",
    "\n",
    "    return Node(feature_index=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
    "```\n",
    "\n",
    "## 树的递归分枝过程简述\n",
    "\n",
    "结合上述代码，树的递归分枝过程可以分为以下步骤：\n",
    "\n",
    "1. **初始化**：\n",
    "   - 从根节点开始，传入整个训练数据集`X`和标签`y`。\n",
    "\n",
    "2. **检查终止条件1（最小样本分裂数）**：\n",
    "   - 如果当前节点的样本数小于`min_samples_split`，则停止分裂，创建叶节点。\n",
    "\n",
    "3. **寻找最佳分裂**：\n",
    "   - 遍历所有特征和可能的阈值，计算每个分裂的收益。\n",
    "   - 选择收益最大的特征和阈值作为当前节点的分裂依据。\n",
    "\n",
    "4. **检查终止条件2（最小不纯度减少）**：\n",
    "   - 如果最佳分裂的收益小于`min_impurity_decrease`，则停止分裂，创建叶节点。\n",
    "\n",
    "5. **进行分裂**：\n",
    "   - 根据最佳特征和阈值，将数据集划分为左子集和右子集。\n",
    "\n",
    "6. **递归构建子树**：\n",
    "   - 对左子集和右子集分别调用`_build_tree`方法，递归地构建左子树和右子树。\n",
    "\n",
    "7. **终止递归**：\n",
    "   - 当所有叶节点都满足终止条件，不再进行分裂时，递归过程结束，决策树构建完成。\n",
    "\n",
    "通过上述递归过程，决策树逐层分裂数据，直到满足预设的终止条件，从而形成一个能够进行分类或回归预测的树模型。\n",
    "\n"
   ],
   "id": "3a7592b8686ced4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
