## 一、线性回归

### [1. 采用 scikit-learn 中的 LinearRegression(最小二乘)线性回归模型对波士顿房价数据集进行预测，分别使用正则方程和随机梯度下降方法建模。](ML1_1.ipynb)

#### 具体内容： 

1. **导入数据**  
   a) 查看数据集的描述、特征名、标签名、数据样本量等信息。  
   b) 获取样本的特征数据和标签数据。

2. **划分数据**  
   - 将数据划分为训练集和测试集。

3. **数据归一化**  
   - 对数据进行归一化处理。

4. **训练模型**  
   a) 使用 sklearn 中线性回归的正规方程（LinearRegression）优化方法建模。  
   b) 使用 sklearn 中线性回归的随机梯度下降（SGDRegressor）优化方法建模。

5. **模型评估（2 个模型）**  
   - 评价指标：MSE 和 R²值。

#### 讨论：

- **讨论一：梯度下降和正规方程两种算法有何不同？**  
   分析梯度下降和正规方程两种算法的差异（计算时间、评价指标对比）与优劣点。提示：Python 中计时器 `timeit.default_timer()` 方法。

- **讨论二：数据归一化对算法有什么影响？**  
   对比使用数据归一化和不使用数据归一化，正规方程和梯度下降算法性能是否有差异？分析原因。

- **讨论三：梯度下降算法中的学习率如何影响其工作？**  
   尝试修改随机梯度下降算法(SGDRegressor)的学习率（eta0），观察参数对模型性能的影响。试分析学习率与模型性能之间的关系。

- **讨论四：模型的泛化能力如何？**  
   1. 分别计算模型在训练样本上性能和在测试样本上的性能，判断模型是过拟合还是欠拟合？  
   2. 数据集划分不同对模型性能是否有影响？可尝试修改方法 `train_test_split` 中的 `test_size` 参数，观察数据集划分对模型性能的影响。  
   3. 尝试使用其他线性回归模型。线性回归模型中除了 `LinearRegression`，还有 `Ridge`（岭回归）、`Lasso`、`Polynomial regression`（多项式回归）等模型，使用不同模型进行建模，观察不同模型训练后的模型权重差异，试分析模型的使用场合。
 

### [2. 使用numpy从零实现线性回归算法，采用梯度下降法（BGD）优化线性回归模型，对波士顿房价进行预测。](ML1_2.ipynb)

#### 具体内容：

1. **导入数据**  
   - 从 `.csv` 文件中导入数据。

2. **划分数据**  
   - 将数据划分为训练集和测试集。

3. **数据归一化**  
   - 对数据进行归一化处理。

4. **训练模型**  
   a) 初始化参数 `w`，可使用 `np.concatenate` 数组拼接函数，将截距与权重参数合并在一起（也可以不拼接合并）。  
   b) 求 `f(x)`。  
   c) 求 `J(w)`。  
   d) 求梯度。  
   e) 更新参数 `w`。  
   (b-e) 的过程经过 `epochs` 次迭代。

5. **画出损失函数随迭代次数的变化曲线**  
   - 通过损失函数变化曲线来观察梯度下降执行情况。

6. **测试集数据进行预测，模型评估**  
   - 评估模型在测试集上的性能。

7. **可视化**  
   - 展示数据拟合的效果。

8. **小批量梯度下降算法（MBGD）的编程实现**  
   - 实现小批量梯度下降（MBGD）。

